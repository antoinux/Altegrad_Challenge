{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proper implementation of first model to be used with cross validation\n",
    "\n",
    "http://dl.acm.org/citation.cfm?doid=2600428.2609514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import operator\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def ap(recommanded, real):\n",
    "    real_set = set(real)\n",
    "    cur = 0.\n",
    "    n = len(recommanded)\n",
    "    ans = 0.\n",
    "    for k in range(1, n+1):\n",
    "        if recommanded[k-1] in real_set:\n",
    "            cur += 1\n",
    "            ans += cur/k\n",
    "    return ans/min(n, len(real))\n",
    "\n",
    "def MAP(recommanded, real):\n",
    "    ans = 0.\n",
    "    for i in range(len(recommanded)):\n",
    "        ans += ap(recommanded[i], real[i])\n",
    "    return ans/len(recommanded)\n",
    "\n",
    "class first_model(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, l=.6, g=.2, n_senders=125, n_people=9874, min_df=10):\n",
    "        self.l = l\n",
    "        self.g = g\n",
    "        self.b = 1-l-g\n",
    "        self.n_senders = n_senders\n",
    "        self.n_people = n_people\n",
    "        self.min_df = min_df\n",
    "        self.graph = np.zeros((n_senders, n_people))\n",
    "        self.vect = CountVectorizer(min_df=min_df, binary=True, stop_words='english')\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Encoding the text messages (might be modified)\n",
    "        X_body = self.vect.fit_transform(X[:,1])\n",
    "        \n",
    "        # Computing social graph\n",
    "        n = len(X)\n",
    "        self.n_train = n\n",
    "        for i in range(n):\n",
    "            sender = X[i][0]\n",
    "            for recipient in y[i]:\n",
    "                self.graph[sender][recipient] += 1\n",
    "\n",
    "        self.total_received = np.sum(self.graph, axis=0)\n",
    "        # if someone never received any message, we put 1 instead of 0 to avoid arthmetical errors...\n",
    "        for i in range(len(self.total_received)):\n",
    "            if self.total_received[i] == 0:\n",
    "                self.total_received[i] = 1\n",
    "        \n",
    "        \n",
    "        # X_body is a document-occurance bag-of-word representation of the text made by the user.\n",
    "        # Computing the probabilities for the text-based part of the model\n",
    "        n_words = X_body.shape[1]\n",
    "        self.fwrs = [defaultdict(lambda: defaultdict(lambda: 0.)) for i in range(n_words)]\n",
    "        self.fwr = [defaultdict(lambda: 0.) for i in range(n_words)]\n",
    "        self.fw = np.array(np.sum(X_body, axis=0))[0].astype(float)\n",
    "        \n",
    "        cx = X_body.tocoo()\n",
    "        for i,j in itertools.izip(cx.row, cx.col):\n",
    "            for recipient_id in y[i]:\n",
    "                self.fwrs[j][X[i][0]][recipient_id] += 1\n",
    "                self.fwr[j][recipient_id] += 1\n",
    "                \n",
    "        # That's the long part\n",
    "        self.terms = [defaultdict(lambda: defaultdict(lambda: 0)) for i in range(n_words)]\n",
    "        for w in range(n_words):\n",
    "            for s,d in self.fwrs[w].iteritems():\n",
    "                for r,v in d.iteritems():\n",
    "                    self.terms[w][s][r] = np.log(self.l*v/max(1., self.graph[s][r])\n",
    "                                                 + self.g*self.fwr[w][r]/self.total_received[r]\n",
    "                                                 + self.b*self.fw[w]/n)\n",
    "                    \n",
    "        self.recipient_lists = [set() for i in range(125)]\n",
    "        for i in range(self.n_senders):\n",
    "            for j in range(self.n_people):\n",
    "                if self.graph[i][j] != 0:\n",
    "                    self.recipient_lists[i].add(j)\n",
    "                    \n",
    "        self.best_recipients = np.argsort(self.total_received)[-10:]\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # Encoding the text messages (might be modified)\n",
    "        X_body = self.vect.transform(X[:,1])\n",
    "        \n",
    "        cxt = X_body.tocoo()\n",
    "        probas = [defaultdict(lambda: 0) for i in range(len(X))]\n",
    "        # This is the longuest part O(W*n_people) = \"O(a_lot*10.000)\"\n",
    "        for i,j in itertools.izip(cxt.row, cxt.col):\n",
    "            s = X[i][0]\n",
    "            for r in self.recipient_lists[s]:\n",
    "                if(probas[i][r] == 0):\n",
    "                    probas[i][r] = np.log(self.graph[s][r])\n",
    "                if self.terms[j][s][r] == 0:\n",
    "                    self.terms[j][s][r] = np.log(self.g*self.fwr[j][r]/self.total_received[r] + self.b*self.fw[j]/self.n_train)\n",
    "                probas[i][r] += self.terms[j][s][r]\n",
    "                \n",
    "        y = np.zeros((X_body.shape[0], 10), dtype=int)\n",
    "        for i in range(len(X)):\n",
    "            bests = sorted(probas[i].iteritems(), key=operator.itemgetter(1), reverse=True)[:10]\n",
    "            for j in range(min(len(bests), 10)):\n",
    "                y[i][j] = bests[j][0]\n",
    "            # If this sender sent mails to less than 10 people, we fill with the most popular recipients.\n",
    "            for j in range(min(len(bests), 10), 10):\n",
    "                y[i][j] = self.best_recipients[j-min(len(bests), 10)]\n",
    "        return y\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return MAP(self.predict(X), y)\n",
    "    \n",
    "    def get_params(self, deep):\n",
    "        return {'l':self.l, 'g':self.g, 'n_senders':self.n_senders, 'n_people':self.n_people, 'min_df':self.min_df}\n",
    "    \n",
    "    def set_params(self, l=.6, g=.2, n_senders=125, n_people=9874, min_df=10):\n",
    "        self.l = l\n",
    "        self.g = g\n",
    "        self.b = 1-l-g\n",
    "        self.n_senders = n_senders\n",
    "        self.n_people = n_people\n",
    "        self.min_df = min_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from time import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df['recipient_id'] = df['recipient_id'].apply(literal_eval)\n",
    "X, y = df[['sender_id', 'body']].values, df['recipient_id'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.6635320187\n"
     ]
    }
   ],
   "source": [
    "model = first_model()\n",
    "start = time()\n",
    "model.fit(X_train, y_train)\n",
    "print time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.592405080795\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "n = 10\n",
    "y_pred = model.predict(X_test[:n])\n",
    "print time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.455980249819\n",
      "182.50704217\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "print model.score(X_test, y_test)\n",
    "print time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {'l':[.5, .6, .7], 'g':[.2]}\n",
    "clf = GridSearchCV(first_model(), parameters, n_jobs=1, cv=10)\n",
    "start = time()\n",
    "clf.fit(X, y)\n",
    "print time() - start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
