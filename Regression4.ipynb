{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv').sort_values('date')\n",
    "df['recipient_id'] = df['recipient_id'].apply(literal_eval)\n",
    "df_test = pd.read_csv('data/test.csv').sort_values('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender</th>\n",
       "      <th>sender_id</th>\n",
       "      <th>mid</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>recipient_id</th>\n",
       "      <th>recipients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5304</th>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>124</td>\n",
       "      <td>47361</td>\n",
       "      <td>0001-08-26 22:16:36</td>\n",
       "      <td>The following reports have been waiting for yo...</td>\n",
       "      <td>[377]</td>\n",
       "      <td>kimberly.watson@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5305</th>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>124</td>\n",
       "      <td>47362</td>\n",
       "      <td>0001-08-27 22:21:02</td>\n",
       "      <td>The following reports have been waiting for yo...</td>\n",
       "      <td>[377]</td>\n",
       "      <td>kimberly.watson@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5306</th>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>124</td>\n",
       "      <td>47363</td>\n",
       "      <td>0001-08-28 22:25:35</td>\n",
       "      <td>The following reports have been waiting for yo...</td>\n",
       "      <td>[377]</td>\n",
       "      <td>kimberly.watson@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5285</th>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>124</td>\n",
       "      <td>45909</td>\n",
       "      <td>0001-09-13 22:24:08</td>\n",
       "      <td>Employee Name: Kimberly WatsonReport Name:   E...</td>\n",
       "      <td>[377]</td>\n",
       "      <td>kimberly.watson@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8934</th>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>124</td>\n",
       "      <td>82030</td>\n",
       "      <td>0001-09-17 09:24:00</td>\n",
       "      <td>The following expense report is ready for appr...</td>\n",
       "      <td>[121]</td>\n",
       "      <td>barry.tycholiz@enron.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 sender  sender_id    mid  \\\n",
       "5304  enron_update@concureworkplace.com        124  47361   \n",
       "5305  enron_update@concureworkplace.com        124  47362   \n",
       "5306  enron_update@concureworkplace.com        124  47363   \n",
       "5285  enron_update@concureworkplace.com        124  45909   \n",
       "8934  enron_update@concureworkplace.com        124  82030   \n",
       "\n",
       "                     date                                               body  \\\n",
       "5304  0001-08-26 22:16:36  The following reports have been waiting for yo...   \n",
       "5305  0001-08-27 22:21:02  The following reports have been waiting for yo...   \n",
       "5306  0001-08-28 22:25:35  The following reports have been waiting for yo...   \n",
       "5285  0001-09-13 22:24:08  Employee Name: Kimberly WatsonReport Name:   E...   \n",
       "8934  0001-09-17 09:24:00  The following expense report is ready for appr...   \n",
       "\n",
       "     recipient_id                 recipients  \n",
       "5304        [377]  kimberly.watson@enron.com  \n",
       "5305        [377]  kimberly.watson@enron.com  \n",
       "5306        [377]  kimberly.watson@enron.com  \n",
       "5285        [377]  kimberly.watson@enron.com  \n",
       "8934        [121]   barry.tycholiz@enron.com  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sara.shackleton@enron.com', 83, 180892, '2000-10-03 01:14:00',\n",
       "       'fax:  713-646-3490\\t\"Susan Hopkinson\" <susan.hopkinson@lovells.com>\\t10/03/2000 07:53 AM\\t\\t \\t\\t To: <Sara.Shackleton@enron.com>\\t\\t cc: \\t\\t Subject: Re: ISDA Master Agreement between Enron North America Corp. andSociieteIndustrielle de Transports Automobile S.A.CONFIDENTIALITY This e-mail and any attachments are confidentialand may also be privileged. If you are not the named recipient,please notify the sender immediately and do not disclose thecontents to another person, use it for any purpose, or storeor copy the information in any medium.----------------------------------------------------------------Please would you send me your fax number.Many thanksSusan----------------------------------------------------------------Lovells (the merged firm of Lovell White Durrant andBoesebeck Droste, practising as Lovells Boesebeck Droste insome jurisdictions) is an international law firm.In the event of any technical difficulty with this email, please contactthe sender or the London Technology Department on +44 (0) 20 7296 2000.',\n",
       "       [6210], 'susan.hopkinson@lovells.com'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values[10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2058, 'chris.germany@enron.com', 22, 347212, '2002-06-24 13:15:28',\n",
       "       '??-----Original Message-----From: Ivy Kao [mailto:ivy_kao@iroquois.com]Sent: Monday, June 24, 2002 3:14 PMTo: Germany, ChrisCc: robin_zaleski@iroquois.comSubject: Capacity releaseHello Chris:I am just curious to find out if you are planning to release the 35,465dth back to Boston Gas this month.  Please let me know.  Thanks.Ivy'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186.328\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "senders_recipients = defaultdict(lambda: set())\n",
    "for l in df.values:\n",
    "    for r in l[5]:\n",
    "        senders_recipients[l[1]].add(r)\n",
    "        \n",
    "c = 0\n",
    "for s, r in senders_recipients.iteritems():\n",
    "    c += len(r)\n",
    "print float(c)/125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48209709.0\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "senders_counts = np.zeros(125)\n",
    "for l in df.values:\n",
    "    senders_counts[l[1]] += 1\n",
    "\n",
    "print np.sum(senders_counts**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks possible (but a bit long) to train one svm per sender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here I implement this idea for each sender, and add the time as 4 additional features.\n",
    "http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim at builing a ranking generator for each sender. For this we use word2vec to get reasonable features, and we interpret the task as a regression task, using one hot encoding on the recipients. Next we might try to train an embedding on the recipients, which seems to be best solution to fit our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def ohe(y):\n",
    "    seen = set()\n",
    "    indexes = []\n",
    "    for l in y:\n",
    "        for r in l:\n",
    "            if not r in seen:\n",
    "                seen.add(r)\n",
    "                indexes.append(r)\n",
    "    rindexes = {indexes[i]: i for i in range(len(indexes))}\n",
    "    \n",
    "    y_ohe = np.zeros((len(y), len(indexes)), dtype=float)\n",
    "    for i in range(len(y)):\n",
    "        l = y[i]\n",
    "        for r in l:\n",
    "            y_ohe[i][rindexes[r]] = 1.\n",
    "    return y_ohe, indexes\n",
    "\n",
    "def make_dataset(df, w2v, d, split_ratio=.1, min_df=10):\n",
    "    stemmer = PorterStemmer\n",
    "    X, X_dates, y = df[['sender_id', 'body']].values, df['date'].values, df['recipient_id'].values\n",
    "    \n",
    "    print \"stemming...\"\n",
    "    stemmer = PorterStemmer()\n",
    "    for i in range(len(X)):\n",
    "        X[i][1] = ' '.join(map(lambda x: str(stemmer.stem(x)), word_tokenize(X[i][1])))\n",
    "    \n",
    "    print \"vectorizing...\"\n",
    "    #vect = CountVectorizer(min_df=min_df, stop_words='english')\n",
    "    vect = TfidfVectorizer(min_df=min_df, stop_words='english')\n",
    "    X_body = vect.fit_transform(X[:,1])\n",
    "    \n",
    "    print \"w2v...\"\n",
    "    voc = vect.vocabulary_\n",
    "    coef = np.array([s if s != 0. else 1. for s in X_body.sum(axis=1)])\n",
    "    translate_matrix = np.empty((len(voc), d), dtype=float)\n",
    "    for w, i in voc.iteritems():\n",
    "        translate_matrix[i] = w2v[w] if w in w2v else np.zeros(d)\n",
    "    vectorized = X_body.dot(translate_matrix)/coef.reshape(-1, 1)\n",
    "    \n",
    "    #date_features = np.array([np.array([s[:4], s[5:7], s[8:10], s[11:13]]) for s in X_dates]).astype(float)\n",
    "    \n",
    "    X_full = vectorized\n",
    "    \n",
    "    X_lol, y_lol = defaultdict(lambda: []), defaultdict(lambda: [])\n",
    "    recipient_indexes = []\n",
    "    for i in range(len(X)):\n",
    "        X_lol[X[i][0]].append(X_full[i])\n",
    "        y_lol[X[i][0]].append(y[i])\n",
    "    \n",
    "    print \"one hot encoding...\"\n",
    "    recipient_indexes = []\n",
    "    for i in range(125):\n",
    "        y_lol[i], indexes = ohe(y_lol[i])\n",
    "        recipient_indexes.append(indexes)\n",
    "        \n",
    "        \n",
    "    X_train, X_test, y_train, y_test = [], [], [], []\n",
    "    \n",
    "    for i in range(125):\n",
    "        cur_X = StandardScaler().fit_transform(np.array(X_lol[i]))\n",
    "        train_size = len(cur_X) - int(.1*len(cur_X))\n",
    "        X_train.append(cur_X[:train_size])\n",
    "        X_test.append(cur_X[train_size:])\n",
    "        cur_y = np.array(y_lol[i])\n",
    "        y_train.append(cur_y[:train_size])\n",
    "        y_test.append(cur_y[train_size:])\n",
    "        if(y_train[i].shape[1] == 1):\n",
    "            y_train[i] = y_train[i].ravel()\n",
    "            y_test[i] = y_test[i].ravel()\n",
    "    \n",
    "    train_size = len(X) - int(.1*len(X))\n",
    "    return X_train, X_test, y_train, y_test, recipient_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"glove.6B.50d.txt\", \"rb\") as lines:\n",
    "    w2v = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "           for line in lines}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stemming...\n",
      "vectorizing...\n",
      "w2v...\n",
      "one hot encoding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daemonginger/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139.912637949\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "start = time()\n",
    "X_train, X_test, y_train, y_test, recipient_indexes = make_dataset(df, w2v, 50)\n",
    "print time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ap(recommanded, real):\n",
    "    real_set = set(real)\n",
    "    cur = 0.\n",
    "    n = len(recommanded)\n",
    "    ans = 0.\n",
    "    for k in range(1, n+1):\n",
    "        if recommanded[k-1] in real_set:\n",
    "            cur += 1\n",
    "            ans += cur/k\n",
    "    return ans/min(n, len(real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 done\n",
      "Next shape is (141, 544)\n",
      "1 done\n",
      "Next shape is (351, 123)\n",
      "2 done\n",
      "Next shape is (79, 152)\n",
      "3 done\n",
      "Next shape is (112, 57)\n",
      "4 done\n",
      "Next shape is (105, 351)\n",
      "5 done\n",
      "Next shape is (75, 63)\n",
      "6 done\n",
      "Next shape is (468, 394)\n",
      "7 done\n",
      "Next shape is (99, 10)\n",
      "8 done\n",
      "Next shape is (311, 841)\n",
      "9 done\n",
      "Next shape is (76, 11)\n",
      "10 done\n",
      "Next shape is (126, 67)\n",
      "11 done\n",
      "Next shape is (63, 56)\n",
      "12 done\n",
      "Next shape is (88, 183)\n",
      "13 done\n",
      "Next shape is (365, 143)\n",
      "14 done\n",
      "Next shape is (270, 399)\n",
      "15 done\n",
      "Next shape is (94, 134)\n",
      "16 done\n",
      "Next shape is (255, 111)\n",
      "17 done\n",
      "Next shape is (546, 200)\n",
      "18 done\n",
      "Next shape is (315, 219)\n",
      "19 done\n",
      "Next shape is (91, 211)\n",
      "20 done\n",
      "Next shape is (153, 354)\n",
      "21 done\n",
      "Next shape is (471, 266)\n",
      "22 done\n",
      "Next shape is (2226, 350)\n",
      "23 done\n",
      "Next shape is (1313, 199)\n",
      "24 done\n",
      "Next shape is (470, 406)\n",
      "25 done\n",
      "Next shape is (681, 273)\n",
      "26 done\n",
      "Next shape is (151, 83)\n",
      "27 done\n",
      "Next shape is (99, 147)\n",
      "28 done\n",
      "Next shape is (400, 151)\n",
      "29 done\n",
      "Next shape is (474, 112)\n",
      "30 done\n",
      "Next shape is (436, 332)\n",
      "31 done\n",
      "Next shape is (383, 135)\n",
      "32 done\n",
      "Next shape is (298, 14)\n",
      "33 done\n",
      "Next shape is (80, 141)\n",
      "34 done\n",
      "Next shape is (313, 248)\n",
      "35 done\n",
      "Next shape is (246, 207)\n",
      "36 done\n",
      "Next shape is (172, 96)\n",
      "37 done\n",
      "Next shape is (359, 214)\n",
      "38 done\n",
      "Next shape is (70,)\n",
      "39 done\n",
      "Next shape is (417, 222)\n",
      "40 done\n",
      "Next shape is (72, 21)\n",
      "41 done\n",
      "Next shape is (80, 59)\n",
      "42 done\n",
      "Next shape is (116, 140)\n",
      "43 done\n",
      "Next shape is (173, 89)\n",
      "44 done\n",
      "Next shape is (227, 140)\n",
      "45 done\n",
      "Next shape is (367, 131)\n",
      "46 done\n",
      "Next shape is (144, 84)\n",
      "47 done\n",
      "Next shape is (134, 72)\n",
      "48 done\n",
      "Next shape is (278, 283)\n",
      "49 done\n",
      "Next shape is (144, 388)\n",
      "50 done\n",
      "Next shape is (521, 177)\n",
      "51 done\n",
      "Next shape is (94, 153)\n",
      "52 done\n",
      "Next shape is (162, 64)\n",
      "53 done\n",
      "Next shape is (61, 61)\n",
      "54 done\n",
      "Next shape is (713, 302)\n",
      "55 done\n",
      "Next shape is (621, 168)\n",
      "56 done\n",
      "Next shape is (76, 95)\n",
      "57 done\n",
      "Next shape is (181,)\n",
      "58 done\n",
      "Next shape is (148, 98)\n",
      "59 done\n",
      "Next shape is (990, 354)\n",
      "60 done\n",
      "Next shape is (97, 88)\n",
      "61 done\n",
      "Next shape is (96, 130)\n",
      "62 done\n",
      "Next shape is (89, 168)\n",
      "63 done\n",
      "Next shape is (138, 160)\n",
      "64 done\n",
      "Next shape is (841, 365)\n",
      "65 done\n",
      "Next shape is (107, 36)\n",
      "66 done\n",
      "Next shape is (1510, 417)\n",
      "67 done\n",
      "Next shape is (624, 337)\n",
      "68 done\n",
      "Next shape is (233, 130)\n",
      "69 done\n",
      "Next shape is (135, 70)\n",
      "70 done\n",
      "Next shape is (125, 86)\n",
      "71 done\n",
      "Next shape is (75, 97)\n",
      "72 done\n",
      "Next shape is (96, 76)\n",
      "73 done\n",
      "Next shape is (133, 205)\n",
      "74 done\n",
      "Next shape is (83,)\n",
      "75 done\n",
      "Next shape is (110, 75)\n",
      "76 done\n",
      "Next shape is (118, 185)\n",
      "77 done\n",
      "Next shape is (190, 87)\n",
      "78 done\n",
      "Next shape is (162, 144)\n",
      "79 done\n",
      "Next shape is (135, 82)\n",
      "80 done\n",
      "Next shape is (66, 40)\n",
      "81 done\n",
      "Next shape is (152, 83)\n",
      "82 done\n",
      "Next shape is (117, 287)\n",
      "83 done\n",
      "Next shape is (3915, 676)\n",
      "84 done\n",
      "Next shape is (313, 176)\n",
      "85 done\n",
      "Next shape is (175, 84)\n",
      "86 done\n",
      "Next shape is (1463, 826)\n",
      "87 done\n",
      "Next shape is (288, 203)\n",
      "88 done\n",
      "Next shape is (313, 284)\n",
      "89 done\n",
      "Next shape is (119, 102)\n",
      "90 done\n",
      "Next shape is (198, 84)\n",
      "91 done\n",
      "Next shape is (134, 273)\n",
      "92 done\n",
      "Next shape is (100, 242)\n",
      "93 done\n",
      "Next shape is (169, 58)\n",
      "94 done\n",
      "Next shape is (113, 57)\n",
      "95 done\n",
      "Next shape is (738, 202)\n",
      "96 done\n",
      "Next shape is (391, 460)\n",
      "97 done\n",
      "Next shape is (81, 152)\n",
      "98 done\n",
      "Next shape is (88, 81)\n",
      "99 done\n",
      "Next shape is (140, 99)\n",
      "100 done\n",
      "Next shape is (107, 77)\n",
      "101 done\n",
      "Next shape is (1284, 1247)\n",
      "102 done\n",
      "Next shape is (202, 99)\n",
      "103 done\n",
      "Next shape is (146, 133)\n",
      "104 done\n",
      "Next shape is (87, 76)\n",
      "105 done\n",
      "Next shape is (109, 245)\n",
      "106 done\n",
      "Next shape is (129, 373)\n",
      "107 done\n",
      "Next shape is (909, 453)\n",
      "108 done\n",
      "Next shape is (187, 125)\n",
      "109 done\n",
      "Next shape is (101, 120)\n",
      "110 done\n",
      "Next shape is (137, 190)\n",
      "111 done\n",
      "Next shape is (160, 185)\n",
      "112 done\n",
      "Next shape is (355, 138)\n",
      "113 done\n",
      "Next shape is (68, 51)\n",
      "114 done\n",
      "Next shape is (73, 26)\n",
      "115 done\n",
      "Next shape is (70, 67)\n",
      "116 done\n",
      "Next shape is (63, 65)\n",
      "117 done\n",
      "Next shape is (160, 176)\n",
      "118 done\n",
      "Next shape is (351, 224)\n",
      "119 done\n",
      "Next shape is (192, 116)\n",
      "120 done\n",
      "Next shape is (835, 249)\n",
      "121 done\n",
      "Next shape is (362, 133)\n",
      "122 done\n",
      "Next shape is (121, 98)\n",
      "123 done\n",
      "Next shape is (89, 73)\n",
      "124 done\n",
      "Next shape is (301, 44)\n",
      "834.426157951\n",
      "Score on test: 0.0766625517137\n",
      "Score on train: 0.177093488155\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "start = time()\n",
    "models = []\n",
    "cur = 0\n",
    "for i in range(125):\n",
    "    print(\"{} done\".format(cur))\n",
    "    print(\"Next shape is {}\".format(y_train[i].shape))\n",
    "    models.append(RandomForestRegressor(n_estimators=50, max_leaf_nodes=300).fit(X_train[i], y_train[i]))\n",
    "    cur += 1\n",
    "print time() - start\n",
    "\n",
    "y_pred = []\n",
    "for i in range(125):\n",
    "    y_pred.append(models[i].predict(X_test[i]))\n",
    "    \n",
    "score, c = 0, 0\n",
    "for i in range(125):\n",
    "    for j in range(len(y_test[i])):\n",
    "        real = np.argsort(y_test[i][j])[-10:]\n",
    "        recommanded = list(np.argsort(y_pred[i][j])[-10:])\n",
    "        while len(recommanded) < 10:\n",
    "            recommanded.append(np.max(recommanded) + 1)\n",
    "        score += ap(recommanded, real)\n",
    "        c += 1\n",
    "\n",
    "print(\"Score on test: {}\".format(score/c))\n",
    "\n",
    "y_pred_train = []\n",
    "for i in range(125):\n",
    "    y_pred_train.append(models[i].predict(X_train[i]))\n",
    "    \n",
    "score, c = 0, 0\n",
    "for i in range(125):\n",
    "    for j in range(len(y_train[i])):\n",
    "        real = np.argsort(y_train[i][j])[-10:]\n",
    "        recommanded = list(np.argsort(y_pred_train[i][j])[-10:])\n",
    "        while len(recommanded) < 10:\n",
    "            recommanded.append(np.max(recommanded) + 1)\n",
    "        score += ap(recommanded, real)\n",
    "        c += 1\n",
    "        \n",
    "print(\"Score on train: {}\".format(score/c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
