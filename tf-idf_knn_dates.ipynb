{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import defaultdict\n",
    "from time import time\n",
    "import scipy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv').sort_values('date')\n",
    "df['recipient_id'] = df['recipient_id'].apply(literal_eval)\n",
    "X, X_time, y = df[['sender_id', 'body', 'date']].values, df['date'].values, df['recipient_id'].values\n",
    "\n",
    "df_test = pd.read_csv('data/test.csv').sort_values('date')\n",
    "X2 = df_test[['sender_id', 'body', 'date', 'mid']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Removing digits from the corpus\n",
    "for i in range(len(X)):\n",
    "    X[i][1] = ''.join([d for d in X[i][1] if not d.isdigit()])\n",
    "    \n",
    "for i in range(len(X2)):\n",
    "    X2[i][1] = ''.join([d for d in X2[i][1] if not d.isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_neighbors = 70\n",
    "X_senders = [[] for i in range(125)]\n",
    "y_senders = [[] for i in range(125)]\n",
    "X_senders2 = [[] for i in range(125)]\n",
    "test_mids = [[] for i in range(125)]\n",
    "X_time = [[] for i in range(125)]\n",
    "X_time2 = [[] for i in range(125)]\n",
    "X_train_text = [[] for i in range(125)]\n",
    "X_test_text = [[] for i in range(125)]\n",
    "\n",
    "vect = TfidfVectorizer(min_df=10)\n",
    "X_body_train = vect.fit_transform(X[:, 1])\n",
    "X_body_test = vect.transform(X2[:, 1])\n",
    "\n",
    "norm1 = scipy.sparse.linalg.norm(X_body_train, axis=1)\n",
    "for i in range(len(norm1)):\n",
    "    if norm1[i] == 0.:\n",
    "        norm1[i] = 1.\n",
    "X_body_train = X_body_train.multiply(scipy.sparse.csr_matrix(1./norm1.reshape(-1, 1)))\n",
    "\n",
    "norm2 = scipy.sparse.linalg.norm(X_body_test, axis=1)\n",
    "for i in range(len(norm2)):\n",
    "    if norm2[i] == 0.:\n",
    "        norm2[i] = 1.\n",
    "X_body_test = X_body_test.multiply(scipy.sparse.csr_matrix(1./norm2.reshape(-1, 1)))\n",
    "\n",
    "for i in range(len(X)):\n",
    "    X_senders[X[i][0]].append(i)\n",
    "    X_time[X[i][0]].append(np.datetime64(X[i][2]))\n",
    "    y_senders[X[i][0]].append(y[i])\n",
    "    X_train_text[X[i][0]].append(X[i][1])\n",
    "    \n",
    "for i in range(len(X2)):\n",
    "    X_senders2[X2[i][0]].append(i)\n",
    "    X_time2[X2[i][0]].append(np.datetime64(X2[i][2]))\n",
    "    test_mids[X2[i][0]].append(X2[i][3])\n",
    "    X_test_text[X2[i][0]].append(X2[i][1])\n",
    "    \n",
    "y_train, X_train_tf, X_test_tf= [], [], []\n",
    "X_train_time, X_test_time = [], []\n",
    "for s in range(125):\n",
    "    X_senders[s] = X_body_train[np.array(X_senders[s]), :]\n",
    "    X_senders2[s] = X_body_test[np.array(X_senders2[s]), :]\n",
    "    X_time[s] = np.array(X_time[s]).astype('int64')\n",
    "    X_time2[s] = np.array(X_time2[s]).astype('int64')\n",
    "    \n",
    "    X_train_time.append(X_time[s])\n",
    "    X_test_time.append(X_time2[s])\n",
    "    X_train_tf.append(X_senders[s])\n",
    "    X_test_tf.append(X_senders2[s])\n",
    "    \n",
    "    y_train.append(y_senders[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recipient_ids = {}\n",
    "for l in df[['recipient_id', 'recipients']].values:\n",
    "    a = l[1].split()\n",
    "    for i in range(len(a)):\n",
    "        recipient_ids[l[0][i]] = a[i]\n",
    "        \n",
    "n_people = max(recipient_ids.keys())+1\n",
    "recipient_names = []\n",
    "for i in range(n_people):\n",
    "    if i not in recipient_ids:\n",
    "        recipient_names.append([])\n",
    "        continue\n",
    "    address = recipient_ids[i]\n",
    "    s = address.split('@')[0].split('.')\n",
    "    if len(s) == 2:\n",
    "        recipient_names.append(s)\n",
    "    else:\n",
    "        recipient_names.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def name_in_header(name, mail):\n",
    "    mail = mail[:30].lower()\n",
    "    for s in name:\n",
    "        if s.lower() in mail:\n",
    "            return 1.\n",
    "    return 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent_by_sender = np.zeros((125, n_people))\n",
    "for s in range(125):\n",
    "    for l in y_train[s]:\n",
    "        for r in l:\n",
    "            sent_by_sender[s][r] += 1\n",
    "s = np.sum(sent_by_sender, axis=1)\n",
    "for i in range(len(s)):\n",
    "    if s[i] == 0.:\n",
    "        s[i] = 1.\n",
    "sent_by_sender /= np.sum(sent_by_sender, axis=1).reshape(-1, 1)\n",
    "\n",
    "baseline = np.argsort(sent_by_sender)[:, ::-1][:, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 156 15177\n",
      "1 390 19386\n",
      "2 87 8146\n",
      "3 124 2750\n",
      "4 116 9898\n",
      "5 83 2635\n",
      "6 519 71638\n",
      "7 109 541\n",
      "8 345 104158\n",
      "9 84 503\n",
      "10 140 3787\n",
      "11 70 2234\n",
      "12 97 11822\n",
      "13 405 13648\n",
      "14 300 60221\n",
      "15 104 9477\n",
      "16 283 12348\n",
      "17 606 24151\n",
      "18 350 29593\n",
      "19 101 14327\n",
      "20 169 44811\n",
      "21 523 32646\n",
      "22 2473 163416\n",
      "23 1458 52935\n",
      "24 522 41401\n",
      "25 756 57809\n",
      "26 167 6683\n",
      "27 109 7046\n",
      "28 444 21307\n",
      "29 526 9996\n",
      "30 484 31675\n",
      "31 425 16564\n",
      "32 331 952\n",
      "33 88 6488\n",
      "34 347 21513\n",
      "35 273 26720\n",
      "36 191 7357\n",
      "37 398 22655\n",
      "38 77 47\n",
      "39 463 42342\n",
      "40 79 982\n",
      "41 88 3076\n",
      "42 128 5501\n",
      "43 192 8440\n",
      "44 252 12607\n",
      "45 407 16646\n",
      "46 159 8495\n",
      "47 148 5503\n",
      "48 308 37778\n",
      "49 159 29895\n",
      "50 578 28647\n",
      "51 104 9057\n",
      "52 180 7150\n",
      "53 67 2246\n",
      "54 792 46070\n",
      "55 690 32117\n",
      "56 84 5060\n",
      "57 201 171\n",
      "58 164 9865\n",
      "59 1099 66999\n",
      "60 107 5017\n",
      "61 106 8254\n",
      "62 98 10407\n",
      "63 153 12436\n",
      "64 934 57817\n",
      "65 118 1267\n",
      "66 1677 163920\n",
      "67 693 57107\n",
      "68 258 13340\n",
      "69 150 4621\n",
      "70 138 6898\n",
      "71 83 4617\n",
      "72 106 4176\n",
      "73 147 16018\n",
      "74 92 62\n",
      "75 122 4817\n",
      "76 131 15255\n",
      "77 211 7054\n",
      "78 180 11386\n",
      "79 150 5812\n",
      "80 73 1711\n",
      "81 168 5688\n",
      "82 129 21748\n",
      "83 4350 207765\n",
      "84 347 51135\n",
      "85 194 8367\n",
      "86 1625 111272\n",
      "87 319 36306\n",
      "88 347 19190\n",
      "89 132 6855\n",
      "90 220 8607\n",
      "91 148 29082\n",
      "92 111 18080\n",
      "93 187 4026\n",
      "94 125 3982\n",
      "95 819 34465\n",
      "96 434 113121\n",
      "97 90 8322\n",
      "98 97 4667\n",
      "99 155 8004\n",
      "100 118 4997\n",
      "101 1426 191512\n",
      "102 224 11928\n",
      "103 162 6611\n",
      "104 96 4094\n",
      "105 121 16226\n",
      "106 143 28787\n",
      "107 1009 93525\n",
      "108 207 10223\n",
      "109 112 8739\n",
      "110 152 19942\n",
      "111 177 21949\n",
      "112 394 16493\n",
      "113 75 1800\n",
      "114 81 1115\n",
      "115 77 3034\n",
      "116 69 2505\n",
      "117 177 20009\n",
      "118 389 28896\n",
      "119 213 9932\n",
      "120 927 39754\n",
      "121 402 17195\n",
      "122 134 6051\n",
      "123 98 3529\n",
      "124 334 6069\n",
      "116.097779989\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from time import time\n",
    "\n",
    "n_neigbhors = 70\n",
    "l = 1.5\n",
    "X_train_full, y_train_full = [], []\n",
    "\n",
    "mail_times = [[[] for j in range(n_people)] for i in range(125)]\n",
    "for s in range(125):\n",
    "    for j in range(len(X_train_time[s])):\n",
    "        for r in y_train[s][j]:\n",
    "            mail_times[s][r].append(X_train_time[s][j])\n",
    "\n",
    "start = time()\n",
    "\n",
    "for s in range(125):\n",
    "    cosine_similarities_matrix = X_train_tf[s].dot(X_train_tf[s].transpose())\n",
    "    #print cosine_similarities_matrix.diagonal()\n",
    "    \n",
    "    X_train, y_train_true = np.empty((0, 7)), np.empty(0)\n",
    "    \n",
    "    for j in range(30, len(X_train_text[s])):\n",
    "        cosine_similarities = np.array(cosine_similarities_matrix[j].todense())[0]\n",
    "            \n",
    "        # don't forget to not take the first one, which is the mail itself and will always have a similarity equal to 1.\n",
    "        closests = np.argsort(cosine_similarities)[::-1][1:n_neighbors+1]\n",
    "        candidates_local_keys = {}\n",
    "        cur = 0\n",
    "        for m in closests:\n",
    "            for r in y_train[s][m]:\n",
    "                if r not in candidates_local_keys:\n",
    "                    candidates_local_keys[r] = cur\n",
    "                    cur += 1\n",
    "        n_candidates = len(candidates_local_keys)\n",
    "        \n",
    "        features = np.zeros((n_candidates, 7))\n",
    "        for m in closests:\n",
    "            for r in y_train[s][m]:\n",
    "                if r in candidates_local_keys:\n",
    "                    features[candidates_local_keys[r]][0] += 1.\n",
    "                    features[candidates_local_keys[r]][1] += cosine_similarities[m]\n",
    "                    features[candidates_local_keys[r]][3] += X_train_time[s][j] - X_train_time[s][m]\n",
    "                    features[candidates_local_keys[r]][5] += cosine_similarities[m]*(X_train_time[s][j] - X_train_time[s][m])\n",
    "        \n",
    "        for r in candidates_local_keys:\n",
    "                features[candidates_local_keys[r]][2] = name_in_header(recipient_names[r], X_train_text[s][j])\n",
    "                features[candidates_local_keys[r]][4] = sent_by_sender[s][r]\n",
    "                    \n",
    "                a = np.array(mail_times[s][r])\n",
    "                #if X_train_time[s][j] in a[a < X_train_time[s][j]]:\n",
    "                #    print 'lol', s, j, r\n",
    "                features[candidates_local_keys[r]][6] = ((X_train_time[s][j] - a[a < X_train_time[s][j]])**(-l)).sum()\n",
    "                if len(mail_times[s][r]) != 0:\n",
    "                    features[candidates_local_keys[r]][6] /= len(mail_times[s][r])\n",
    "                \n",
    "        for i in range(n_candidates):\n",
    "            if features[i][0] == 0.:\n",
    "                features[i][0] = 1.\n",
    "        \n",
    "        features[:, 1] /= features[:, 0]\n",
    "        features[:, 3] /= features[:, 0]\n",
    "        features[:, 0] /= len(closests)\n",
    "        \n",
    "        X_train = np.vstack((X_train, features))\n",
    "        \n",
    "        y_mail = np.zeros(n_candidates)\n",
    "        for r in candidates_local_keys:\n",
    "            y_mail[candidates_local_keys[r]] = 1. if r in y_train[s][j] else 0.\n",
    "        \n",
    "        y_train_true = np.hstack((y_train_true, y_mail))\n",
    "    \n",
    "    X_train_full.append(X_train)\n",
    "    y_train_full.append(y_train_true)\n",
    "    print s, len(X_train_text[s]), len(X_train)\n",
    "print time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "8.21510601044\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from time import time\n",
    "\n",
    "start = time()\n",
    "\n",
    "n_neigbhors = 70\n",
    "l = 1.5\n",
    "X_test_full, starting_ids, keys_to_rs = [], [], []\n",
    "\n",
    "for s in range(125):\n",
    "    cosine_similarities_matrix = X_test_tf[s].dot(X_train_tf[s].transpose())\n",
    "    y_pred_sender = np.empty((len(X_test_text[s]), 10))\n",
    "    \n",
    "    X_test_sender = np.empty((0, 7))\n",
    "    sender_starting_ids = []\n",
    "    sender_keys_to_r = []\n",
    "\n",
    "    for j in range(len(X_test_text[s])):\n",
    "        sender_starting_ids.append(len(X_test_sender))\n",
    "        cosine_similarities = np.array(cosine_similarities_matrix[j].todense())[0]\n",
    "\n",
    "        closests = np.argsort(cosine_similarities)[::-1][:n_neighbors]\n",
    "\n",
    "        candidates_local_keys = {}\n",
    "        cur = 0\n",
    "        for m in closests:\n",
    "            for r in y_train[s][m]:\n",
    "                if r not in candidates_local_keys:\n",
    "                    candidates_local_keys[r] = cur\n",
    "                    cur += 1\n",
    "        n_candidates = len(candidates_local_keys)\n",
    "\n",
    "        features = np.zeros((n_candidates, 7))\n",
    "        for m in closests:\n",
    "            for r in y_train[s][m]:\n",
    "                if r in candidates_local_keys:\n",
    "                    features[candidates_local_keys[r]][0] += 1.\n",
    "                    features[candidates_local_keys[r]][1] += cosine_similarities[m]\n",
    "                    features[candidates_local_keys[r]][3] += X_test_time[s][j] - X_train_time[s][m]\n",
    "                    features[candidates_local_keys[r]][5] += cosine_similarities[m]*(X_test_time[s][j] - X_train_time[s][m])\n",
    "\n",
    "        for r in candidates_local_keys:\n",
    "                features[candidates_local_keys[r]][2] = name_in_header(recipient_names[r], X_test_text[s][j])\n",
    "                features[candidates_local_keys[r]][4] = sent_by_sender[s][r]\n",
    "                \n",
    "                a = np.array(mail_times[s][r])\n",
    "                #if X_train_time[s][j] in a[a < X_train_time[s][j]]:\n",
    "                #    print 'lol', s, j, r\n",
    "                features[candidates_local_keys[r]][6] = ((X_test_time[s][j] - a[a < X_test_time[s][j]])**(-l)).sum()\n",
    "                if len(mail_times[s][r]) != 0:\n",
    "                    features[candidates_local_keys[r]][6] /= len(mail_times[s][r])\n",
    "\n",
    "        for i in range(n_candidates):\n",
    "            if features[i][0] == 0.:\n",
    "                features[i][0] = 1.\n",
    "\n",
    "        features[:, 1] /= features[:, 0]\n",
    "        features[:, 3] /= features[:, 0]\n",
    "        features[:, 0] /= len(closests)\n",
    "\n",
    "        X_test_sender = np.vstack((X_test_sender, features))\n",
    "        \n",
    "        keys_to_r = {candidates_local_keys[r]:r for r in candidates_local_keys}\n",
    "        sender_keys_to_r.append(keys_to_r)\n",
    "    \n",
    "    X_test_full.append(X_test_sender)\n",
    "    sender_starting_ids.append(len(X_test_sender))\n",
    "    starting_ids.append(sender_starting_ids)\n",
    "    keys_to_rs.append(sender_keys_to_r)\n",
    "    print s\n",
    "print time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "max_leaf_nodes = 40\n",
    "n_estimators = 500\n",
    "for s in range(125):\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators, max_leaf_nodes=max_leaf_nodes, n_jobs=-1).fit(X_train_full[s], y_train_full[s])\n",
    "        \n",
    "    y_pred_sender = np.empty((len(X_test_text[s]), 10))\n",
    "        \n",
    "    if len(X_test_text[s]) == 0:\n",
    "            pass\n",
    "    elif clf.n_classes_ == 1:\n",
    "        y_pred_sender = np.array([baseline[s] for i in range(len(X_test_text[s]))])\n",
    "    else:\n",
    "        \n",
    "        raw_pred = clf.predict_proba(X_test_full[s])[:, 1]\n",
    "            \n",
    "        for j in range(len(X_test_text[s])):\n",
    "            pre = list(raw_pred[starting_ids[s][j]:starting_ids[s][j+1]].argsort()[::-1][:10])\n",
    "            for i in range(len(pre)):\n",
    "                pre[i] = keys_to_rs[s][j][pre[i]]\n",
    "\n",
    "            # if we don't have enough candidates, fill with baseline\n",
    "            cur = 0\n",
    "            while len(pre) < 10:\n",
    "                if baseline[s][cur] not in keys_to_rs[s][j].values():\n",
    "                    pre.append(baseline[s][cur])\n",
    "                cur += 1\n",
    "            y_pred_sender[j] = np.array(pre)\n",
    "    y_pred.append(y_pred_sender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recipient_ids = {}\n",
    "for l in df[['recipient_id', 'recipients']].values:\n",
    "    a = l[1].split()\n",
    "    for i in range(len(a)):\n",
    "        recipient_ids[l[0][i]] = a[i]\n",
    "        \n",
    "with open('data/sub_tfidf_knn_dates_two_more_features_RF_1.txt', 'w') as f:\n",
    "    f.write('mid,recipients\\n')\n",
    "    for s in range(125):\n",
    "        for i in range(len(y_pred[s])):\n",
    "            f.write('{},'.format(test_mids[s][i]))\n",
    "            for r in y_pred[s][i]:\n",
    "                f.write(recipient_ids[r] + ' ')\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When augmenting number of trees from 50 to 200 and reducing number of leaf nodes from 50 to 40 the score got higher. Which could we were overfiting or that we just needed more trees.\n",
    "\n",
    "Using xgboost might be the way to pass the 0.4 bar !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Let's try some validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import defaultdict\n",
    "from time import time\n",
    "import scipy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv').sort_values('date')\n",
    "df['recipient_id'] = df['recipient_id'].apply(literal_eval)\n",
    "\n",
    "train_size = len(df) - int((.1*len(df)))\n",
    "\n",
    "X, X_time, y = df[['sender_id', 'body', 'date']].values[:train_size], df['date'].values[:train_size], df['recipient_id'].values[:train_size]\n",
    "\n",
    "X2 = df[['sender_id', 'body', 'date', 'mid']].values[train_size:]\n",
    "\n",
    "y_final_test = [[] for i in range(125)]\n",
    "A = df['recipient_id'].values[train_size:]\n",
    "for i in range(len(A)):\n",
    "    y_final_test[X2[i][0]].append(A[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 97 11313\n",
      "1 343 16634\n",
      "2 75 6534\n",
      "3 122 2711\n",
      "4 103 10195\n",
      "5 80 2540\n",
      "6 382 50753\n",
      "7 102 432\n",
      "8 338 101477\n",
      "9 58 222\n",
      "10 122 2437\n",
      "11 65 1255\n",
      "12 83 9613\n",
      "13 377 12408\n",
      "14 284 57382\n",
      "15 40 1139\n",
      "16 156 6475\n",
      "17 522 21480\n",
      "18 327 26650\n",
      "19 89 11945\n",
      "20 162 42759\n",
      "21 513 32081\n",
      "22 2408 158503\n",
      "23 1441 51977\n",
      "24 508 40243\n",
      "25 683 53136\n",
      "26 147 6067\n",
      "27 106 6913\n",
      "28 400 19435\n",
      "29 432 3635\n",
      "30 450 29796\n",
      "31 399 15585\n",
      "32 156 133\n",
      "33 71 2732\n",
      "34 339 20935\n",
      "35 260 24628\n",
      "36 172 6662\n",
      "37 336 18691\n",
      "38 77 47\n",
      "39 368 32333\n",
      "40 45 254\n",
      "41 78 2442\n",
      "42 103 5233\n",
      "43 165 6874\n",
      "44 223 11442\n",
      "45 379 15612\n",
      "46 103 4431\n",
      "47 134 4806\n",
      "48 271 38965\n",
      "49 145 26633\n",
      "50 499 24537\n",
      "51 94 7859\n",
      "52 161 6413\n",
      "53 57 1555\n",
      "54 754 44453\n",
      "55 548 24648\n",
      "56 72 3857\n",
      "57 191 161\n",
      "58 135 7769\n",
      "59 1010 60677\n",
      "60 92 4371\n",
      "61 105 8026\n",
      "62 98 10412\n",
      "63 150 12426\n",
      "64 842 51205\n",
      "65 114 1222\n",
      "66 1390 138814\n",
      "67 563 44164\n",
      "68 234 12263\n",
      "69 115 3165\n",
      "70 131 6134\n",
      "71 57 2202\n",
      "72 102 3964\n",
      "73 142 15443\n",
      "74 68 38\n",
      "75 119 4525\n",
      "76 79 8232\n",
      "77 184 6016\n",
      "78 166 10523\n",
      "79 138 5109\n",
      "80 56 959\n",
      "81 155 5270\n",
      "82 120 20901\n",
      "83 4211 201529\n",
      "84 310 44565\n",
      "85 137 3225\n",
      "86 1609 110922\n",
      "87 215 24144\n",
      "88 313 16300\n",
      "89 121 6057\n",
      "90 201 7886\n",
      "91 142 27652\n",
      "92 91 13825\n",
      "93 165 3088\n",
      "94 107 3267\n",
      "95 796 33613\n",
      "96 367 100509\n",
      "97 84 7184\n",
      "98 89 3813\n",
      "99 139 6994\n",
      "100 107 4495\n",
      "101 1350 174352\n",
      "102 217 11301\n",
      "103 118 4348\n",
      "104 88 3595\n",
      "105 113 15170\n",
      "106 141 28048\n",
      "107 978 92428\n",
      "108 207 10168\n",
      "109 92 6660\n",
      "110 114 10340\n",
      "111 163 19786\n",
      "112 327 13496\n",
      "113 67 1809\n",
      "114 77 1052\n",
      "115 50 1257\n",
      "116 41 476\n",
      "117 144 15502\n",
      "118 330 23177\n",
      "119 211 9834\n",
      "120 862 36341\n",
      "121 293 11895\n",
      "122 132 5919\n",
      "123 93 3314\n",
      "124 260 3923\n",
      "108.430866003\n"
     ]
    }
   ],
   "source": [
    "# Removing digits from the corpus\n",
    "for i in range(len(X)):\n",
    "    X[i][1] = ''.join([d for d in X[i][1] if not d.isdigit()])\n",
    "    \n",
    "for i in range(len(X2)):\n",
    "    X2[i][1] = ''.join([d for d in X2[i][1] if not d.isdigit()])\n",
    "    \n",
    "n_neighbors = 70\n",
    "X_senders = [[] for i in range(125)]\n",
    "y_senders = [[] for i in range(125)]\n",
    "X_senders2 = [[] for i in range(125)]\n",
    "test_mids = [[] for i in range(125)]\n",
    "X_time = [[] for i in range(125)]\n",
    "X_time2 = [[] for i in range(125)]\n",
    "X_train_text = [[] for i in range(125)]\n",
    "X_test_text = [[] for i in range(125)]\n",
    "\n",
    "vect = TfidfVectorizer(min_df=10)\n",
    "X_body_train = vect.fit_transform(X[:, 1])\n",
    "X_body_test = vect.transform(X2[:, 1])\n",
    "\n",
    "norm1 = scipy.sparse.linalg.norm(X_body_train, axis=1)\n",
    "for i in range(len(norm1)):\n",
    "    if norm1[i] == 0.:\n",
    "        norm1[i] = 1.\n",
    "X_body_train = X_body_train.multiply(scipy.sparse.csr_matrix(1./norm1.reshape(-1, 1)))\n",
    "\n",
    "norm2 = scipy.sparse.linalg.norm(X_body_test, axis=1)\n",
    "for i in range(len(norm2)):\n",
    "    if norm2[i] == 0.:\n",
    "        norm2[i] = 1.\n",
    "X_body_test = X_body_test.multiply(scipy.sparse.csr_matrix(1./norm2.reshape(-1, 1)))\n",
    "\n",
    "for i in range(len(X)):\n",
    "    X_senders[X[i][0]].append(i)\n",
    "    X_time[X[i][0]].append(np.datetime64(X[i][2]))\n",
    "    y_senders[X[i][0]].append(y[i])\n",
    "    X_train_text[X[i][0]].append(X[i][1])\n",
    "    \n",
    "for i in range(len(X2)):\n",
    "    X_senders2[X2[i][0]].append(i)\n",
    "    X_time2[X2[i][0]].append(np.datetime64(X2[i][2]))\n",
    "    test_mids[X2[i][0]].append(X2[i][3])\n",
    "    X_test_text[X2[i][0]].append(X2[i][1])\n",
    "    \n",
    "y_train, X_train_tf, X_test_tf= [], [], []\n",
    "X_train_time, X_test_time = [], []\n",
    "for s in range(125):\n",
    "    X_senders[s] = X_body_train[np.array(X_senders[s]), :]\n",
    "    X_senders2[s] = X_body_test[np.array(X_senders2[s]), :]\n",
    "    X_time[s] = np.array(X_time[s]).astype('int64')\n",
    "    X_time2[s] = np.array(X_time2[s]).astype('int64')\n",
    "    \n",
    "    X_train_time.append(X_time[s])\n",
    "    X_test_time.append(X_time2[s])\n",
    "    X_train_tf.append(X_senders[s])\n",
    "    X_test_tf.append(X_senders2[s])\n",
    "    \n",
    "    y_train.append(y_senders[s])\n",
    "    \n",
    "    \n",
    "    \n",
    "recipient_ids = {}\n",
    "for l in df[['recipient_id', 'recipients']].values:\n",
    "    a = l[1].split()\n",
    "    for i in range(len(a)):\n",
    "        recipient_ids[l[0][i]] = a[i]\n",
    "        \n",
    "n_people = max(recipient_ids.keys())+1\n",
    "recipient_names = []\n",
    "for i in range(n_people):\n",
    "    if i not in recipient_ids:\n",
    "        recipient_names.append([])\n",
    "        continue\n",
    "    address = recipient_ids[i]\n",
    "    s = address.split('@')[0].split('.')\n",
    "    if len(s) == 2:\n",
    "        recipient_names.append(s)\n",
    "    else:\n",
    "        recipient_names.append([])\n",
    "        \n",
    "def name_in_header(name, mail):\n",
    "    mail = mail[:30].lower()\n",
    "    for s in name:\n",
    "        if s.lower() in mail:\n",
    "            return 1.\n",
    "    return 0.\n",
    "\n",
    "\n",
    "sent_by_sender = np.zeros((125, n_people))\n",
    "for s in range(125):\n",
    "    for l in y_train[s]:\n",
    "        for r in l:\n",
    "            sent_by_sender[s][r] += 1\n",
    "s = np.sum(sent_by_sender, axis=1)\n",
    "for i in range(len(s)):\n",
    "    if s[i] == 0.:\n",
    "        s[i] = 1.\n",
    "sent_by_sender /= np.sum(sent_by_sender, axis=1).reshape(-1, 1)\n",
    "\n",
    "baseline = np.argsort(sent_by_sender)[:, ::-1][:, :10]\n",
    "\n",
    "from time import time\n",
    "\n",
    "n_neigbhors = 70\n",
    "l = 1.5\n",
    "X_train_full, y_train_full = [], []\n",
    "\n",
    "start = time()\n",
    "\n",
    "mail_times = [[[] for j in range(n_people)] for i in range(125)]\n",
    "for s in range(125):\n",
    "    for j in range(len(X_train_time[s])):\n",
    "        for r in y_train[s][j]:\n",
    "            mail_times[s][r].append(X_train_time[s][j])\n",
    "\n",
    "for s in range(125):\n",
    "    cosine_similarities_matrix = X_train_tf[s].dot(X_train_tf[s].transpose())\n",
    "    #print cosine_similarities_matrix.diagonal()\n",
    "    \n",
    "    X_train, y_train_true = np.empty((0, 7)), np.empty(0)\n",
    "    \n",
    "    for j in range(30, len(X_train_text[s])):\n",
    "        cosine_similarities = np.array(cosine_similarities_matrix[j].todense())[0]\n",
    "            \n",
    "        # don't forget to not take the first one, which is the mail itself and will always have a similarity equal to 1.\n",
    "        closests = np.argsort(cosine_similarities)[::-1][1:n_neighbors+1]\n",
    "        candidates_local_keys = {}\n",
    "        cur = 0\n",
    "        for m in closests:\n",
    "            for r in y_train[s][m]:\n",
    "                if r not in candidates_local_keys:\n",
    "                    candidates_local_keys[r] = cur\n",
    "                    cur += 1\n",
    "        n_candidates = len(candidates_local_keys)\n",
    "        \n",
    "        features = np.zeros((n_candidates, 7))\n",
    "        for m in closests:\n",
    "            for r in y_train[s][m]:\n",
    "                if r in candidates_local_keys:\n",
    "                    features[candidates_local_keys[r]][0] += 1.\n",
    "                    features[candidates_local_keys[r]][1] += cosine_similarities[m]\n",
    "                    features[candidates_local_keys[r]][3] += X_train_time[s][j] - X_train_time[s][m]\n",
    "                    features[candidates_local_keys[r]][5] += cosine_similarities[m]*(X_train_time[s][j] - X_train_time[s][m])\n",
    "        \n",
    "        for r in candidates_local_keys:\n",
    "                features[candidates_local_keys[r]][2] = name_in_header(recipient_names[r], X_train_text[s][j])\n",
    "                features[candidates_local_keys[r]][4] = sent_by_sender[s][r]\n",
    "                    \n",
    "                a = np.array(mail_times[s][r])\n",
    "                #if X_train_time[s][j] in a[a < X_train_time[s][j]]:\n",
    "                #    print 'lol', s, j, r\n",
    "                features[candidates_local_keys[r]][6] = ((X_train_time[s][j] - a[a < X_train_time[s][j]])**(-l)).sum()\n",
    "                if len(mail_times[s][r]) != 0:\n",
    "                    features[candidates_local_keys[r]][6] /= len(mail_times[s][r])\n",
    "                \n",
    "        for i in range(n_candidates):\n",
    "            if features[i][0] == 0.:\n",
    "                features[i][0] = 1.\n",
    "        \n",
    "        features[:, 1] /= features[:, 0]\n",
    "        features[:, 3] /= features[:, 0]\n",
    "        features[:, 0] /= len(closests)\n",
    "        \n",
    "        X_train = np.vstack((X_train, features))\n",
    "        \n",
    "        y_mail = np.zeros(n_candidates)\n",
    "        for r in candidates_local_keys:\n",
    "            y_mail[candidates_local_keys[r]] = 1. if r in y_train[s][j] else 0.\n",
    "        \n",
    "        y_train_true = np.hstack((y_train_true, y_mail))\n",
    "    \n",
    "    X_train_full.append(X_train)\n",
    "    y_train_full.append(y_train_true)\n",
    "    print s, len(X_train_text[s]), len(X_train)\n",
    "print time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n"
     ]
    }
   ],
   "source": [
    "X_test_full, starting_ids, keys_to_rs = [], [], []\n",
    "\n",
    "for s in range(125):\n",
    "    cosine_similarities_matrix = X_test_tf[s].dot(X_train_tf[s].transpose())\n",
    "    y_pred_sender = np.empty((len(X_test_text[s]), 10))\n",
    "    \n",
    "    X_test_sender = np.empty((0, 7))\n",
    "    sender_starting_ids = []\n",
    "    sender_keys_to_r = []\n",
    "\n",
    "    for j in range(len(X_test_text[s])):\n",
    "        sender_starting_ids.append(len(X_test_sender))\n",
    "        cosine_similarities = np.array(cosine_similarities_matrix[j].todense())[0]\n",
    "\n",
    "        closests = np.argsort(cosine_similarities)[::-1][:n_neighbors]\n",
    "\n",
    "        candidates_local_keys = {}\n",
    "        cur = 0\n",
    "        for m in closests:\n",
    "            for r in y_train[s][m]:\n",
    "                if r not in candidates_local_keys:\n",
    "                    candidates_local_keys[r] = cur\n",
    "                    cur += 1\n",
    "        n_candidates = len(candidates_local_keys)\n",
    "\n",
    "        features = np.zeros((n_candidates, 7))\n",
    "        for m in closests:\n",
    "            for r in y_train[s][m]:\n",
    "                if r in candidates_local_keys:\n",
    "                    features[candidates_local_keys[r]][0] += 1.\n",
    "                    features[candidates_local_keys[r]][1] += cosine_similarities[m]\n",
    "                    features[candidates_local_keys[r]][3] += X_test_time[s][j] - X_train_time[s][m]\n",
    "                    features[candidates_local_keys[r]][5] += cosine_similarities[m]*(X_test_time[s][j] - X_train_time[s][m])\n",
    "\n",
    "        for r in candidates_local_keys:\n",
    "                features[candidates_local_keys[r]][2] = name_in_header(recipient_names[r], X_test_text[s][j])\n",
    "                features[candidates_local_keys[r]][4] = sent_by_sender[s][r]\n",
    "                \n",
    "                a = np.array(mail_times[s][r])\n",
    "                #if X_train_time[s][j] in a[a < X_train_time[s][j]]:\n",
    "                #    print 'lol', s, j, r\n",
    "                features[candidates_local_keys[r]][6] = ((X_test_time[s][j] - a[a < X_test_time[s][j]])**(-l)).sum()\n",
    "                if len(mail_times[s][r]) != 0:\n",
    "                    features[candidates_local_keys[r]][6] /= len(mail_times[s][r])\n",
    "\n",
    "        for i in range(n_candidates):\n",
    "            if features[i][0] == 0.:\n",
    "                features[i][0] = 1.\n",
    "\n",
    "        features[:, 1] /= features[:, 0]\n",
    "        features[:, 3] /= features[:, 0]\n",
    "        features[:, 0] /= len(closests)\n",
    "\n",
    "        X_test_sender = np.vstack((X_test_sender, features))\n",
    "        \n",
    "        keys_to_r = {candidates_local_keys[r]:r for r in candidates_local_keys}\n",
    "        sender_keys_to_r.append(keys_to_r)\n",
    "    \n",
    "    X_test_full.append(X_test_sender)\n",
    "    sender_starting_ids.append(len(X_test_sender))\n",
    "    starting_ids.append(sender_starting_ids)\n",
    "    keys_to_rs.append(sender_keys_to_r)\n",
    "    print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed = 378.560666084\n",
      "max_leaf_nodes = 10, score = 0.37931250043\n",
      "Time elapsed = 392.004215956\n",
      "max_leaf_nodes = 20, score = 0.38477198702\n",
      "Time elapsed = 397.803869963\n",
      "max_leaf_nodes = 30, score = 0.38585974604\n",
      "Time elapsed = 412.018404007\n",
      "max_leaf_nodes = 40, score = 0.387989604491\n",
      "Time elapsed = 409.016401052\n",
      "max_leaf_nodes = 50, score = 0.386617896883\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-ea0af65ba3b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m125\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0my_pred_sender\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daemonginger/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 tree = self._make_estimator(append=False,\n\u001b[0;32m--> 314\u001b[0;31m                                             random_state=random_state)\n\u001b[0m\u001b[1;32m    315\u001b[0m                 \u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daemonginger/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/base.pyc\u001b[0m in \u001b[0;36m_make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0m_set_random_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daemonginger/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/base.pyc\u001b[0m in \u001b[0;36m_set_random_states\u001b[0;34m(estimator, random_state)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mto_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'random_state'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__random_state'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mto_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_RAND_SEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daemonginger/anaconda2/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[1;32m    234\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m             \u001b[0;31m# We need deprecation warnings to always be on in order to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;31m# catch deprecated param values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daemonginger/anaconda2/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36m_get_param_names\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;31m# introspect the constructor arguments to find the model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;31m# to represent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0minit_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         parameters = [p for p in init_signature.parameters.values()\n",
      "\u001b[0;32m/home/daemonginger/anaconda2/lib/python2.7/site-packages/sklearn/externals/funcsigs.pyc\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__self__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;31m# Unbound method: the first parameter becomes positional-only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                 first = sig.parameters.values()[0].replace(\n\u001b[1;32m     67\u001b[0m                     kind=_POSITIONAL_ONLY)\n",
      "\u001b[0;32m/home/daemonginger/anaconda2/lib/python2.7/site-packages/sklearn/externals/funcsigs.pyc\u001b[0m in \u001b[0;36mparameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMappingProxyType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daemonginger/anaconda2/lib/python2.7/collections.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_setitem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setitem__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/daemonginger/anaconda2/lib/python2.7/_abcoll.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    569\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from time import time\n",
    "\n",
    "def ap(recommanded, real):\n",
    "    real_set = set(real)\n",
    "    cur = 0.\n",
    "    n = len(recommanded)\n",
    "    ans = 0.\n",
    "    for k in range(1, n+1):\n",
    "        if recommanded[k-1] in real_set:\n",
    "            cur += 1\n",
    "            ans += cur/k\n",
    "    return ans/min(n, len(real))\n",
    "\n",
    "def MAP(recommanded, real):\n",
    "    ans = 0.\n",
    "    for i in range(len(recommanded)):\n",
    "        ans += ap(recommanded[i], real[i])\n",
    "    return ans/len(recommanded)\n",
    "\n",
    "for max_leaf_nodes in [10, 20, 30, 40, 50, 60, 70]:\n",
    "    start = time()\n",
    "    y_pred = []\n",
    "    for s in range(125):\n",
    "        clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=max_leaf_nodes, n_jobs=-1).fit(X_train_full[s], y_train_full[s])\n",
    "        \n",
    "        y_pred_sender = np.empty((len(X_test_text[s]), 10))\n",
    "        \n",
    "        if len(X_test_text[s]) == 0:\n",
    "               pass\n",
    "        elif clf.n_classes_ == 1:\n",
    "            y_pred_sender = np.array([baseline[s] for i in range(len(X_test_text[s]))])\n",
    "        else:\n",
    "            \n",
    "            raw_pred = clf.predict_proba(X_test_full[s])[:, 1]\n",
    "            \n",
    "            for j in range(len(X_test_text[s])):\n",
    "                pre = list(raw_pred[starting_ids[s][j]:starting_ids[s][j+1]].argsort()[::-1][:10])\n",
    "                for i in range(len(pre)):\n",
    "                    pre[i] = keys_to_rs[s][j][pre[i]]\n",
    "\n",
    "                # if we don't have enough candidates, fill with baseline\n",
    "                cur = 0\n",
    "                while len(pre) < 10:\n",
    "                    if baseline[s][cur] not in keys_to_rs[s][j].values():\n",
    "                        pre.append(baseline[s][cur])\n",
    "                    cur += 1\n",
    "                y_pred_sender[j] = np.array(pre)\n",
    "        y_pred.append(y_pred_sender)\n",
    "        \n",
    "        \n",
    "    score = 0.\n",
    "    c = 0.\n",
    "    for s in range(125):\n",
    "        c += len(y_pred[s])\n",
    "        for j in range(len(y_pred[s])):\n",
    "            score += ap(y_pred[s][j], y_final_test[s][j])\n",
    "\n",
    "    print \"Time elapsed = {}\".format(time() - start)\n",
    "    print \"max_leaf_nodes = {}, score = {}\".format(max_leaf_nodes, score/c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With RF:\n",
    "\n",
    "n_estimators = 500\n",
    "\n",
    "max_leaf_nodes = 10, score = 0.376055204752\n",
    "\n",
    "max_leaf_nodes = 20, score = 0.380046711475\n",
    "\n",
    "max_leaf_nodes = 30, score = 0.381856818218\n",
    "\n",
    "max_leaf_nodes = 40, score = 0.381058513544\n",
    "\n",
    "max_leaf_nodes = 50, score = 0.384284125066\n",
    "\n",
    "max_leaf_nodes = 60, score = 0.381552354931\n",
    "\n",
    "max_leaf_nodes = 70, score = 0.382649338012\n",
    "\n",
    "n_estimators = 200\n",
    "\n",
    "max_leaf_nodes = 20, score = 0.379784765737\n",
    "\n",
    "max_leaf_nodes = 30, score = 0.379737073331\n",
    "\n",
    "max_leaf_nodes = 40, score = 0.37990337857\n",
    "\n",
    "max_leaf_nodes = 50, score = 0.38024079325\n",
    "\n",
    "max_leaf_nodes = 60, score = 0.378710003567"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ap(recommanded, real):\n",
    "    real_set = set(real)\n",
    "    cur = 0.\n",
    "    n = len(recommanded)\n",
    "    ans = 0.\n",
    "    for k in range(1, n+1):\n",
    "        if recommanded[k-1] in real_set:\n",
    "            cur += 1\n",
    "            ans += cur/k\n",
    "    return ans/min(n, len(real))\n",
    "\n",
    "def MAP(recommanded, real):\n",
    "    ans = 0.\n",
    "    for i in range(len(recommanded)):\n",
    "        ans += ap(recommanded[i], real[i])\n",
    "    return ans/len(recommanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3639194329296734"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = 0.\n",
    "c = 0.\n",
    "for s in range(s):\n",
    "    c += len(y_pred[s])\n",
    "    for j in range(len(y_pred[s])):\n",
    "        score += ap(y_pred[s][j], y_final_test[s][j])\n",
    "\n",
    "score/c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
