{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv').sort_values('date')\n",
    "df['recipient_id'] = df['recipient_id'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender</th>\n",
       "      <th>sender_id</th>\n",
       "      <th>mid</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>recipient_id</th>\n",
       "      <th>recipients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5304</th>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>124</td>\n",
       "      <td>47361</td>\n",
       "      <td>0001-08-26 22:16:36</td>\n",
       "      <td>The following reports have been waiting for yo...</td>\n",
       "      <td>[377]</td>\n",
       "      <td>kimberly.watson@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5305</th>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>124</td>\n",
       "      <td>47362</td>\n",
       "      <td>0001-08-27 22:21:02</td>\n",
       "      <td>The following reports have been waiting for yo...</td>\n",
       "      <td>[377]</td>\n",
       "      <td>kimberly.watson@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5306</th>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>124</td>\n",
       "      <td>47363</td>\n",
       "      <td>0001-08-28 22:25:35</td>\n",
       "      <td>The following reports have been waiting for yo...</td>\n",
       "      <td>[377]</td>\n",
       "      <td>kimberly.watson@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5285</th>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>124</td>\n",
       "      <td>45909</td>\n",
       "      <td>0001-09-13 22:24:08</td>\n",
       "      <td>Employee Name: Kimberly WatsonReport Name:   E...</td>\n",
       "      <td>[377]</td>\n",
       "      <td>kimberly.watson@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8934</th>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>124</td>\n",
       "      <td>82030</td>\n",
       "      <td>0001-09-17 09:24:00</td>\n",
       "      <td>The following expense report is ready for appr...</td>\n",
       "      <td>[121]</td>\n",
       "      <td>barry.tycholiz@enron.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 sender  sender_id    mid  \\\n",
       "5304  enron_update@concureworkplace.com        124  47361   \n",
       "5305  enron_update@concureworkplace.com        124  47362   \n",
       "5306  enron_update@concureworkplace.com        124  47363   \n",
       "5285  enron_update@concureworkplace.com        124  45909   \n",
       "8934  enron_update@concureworkplace.com        124  82030   \n",
       "\n",
       "                     date                                               body  \\\n",
       "5304  0001-08-26 22:16:36  The following reports have been waiting for yo...   \n",
       "5305  0001-08-27 22:21:02  The following reports have been waiting for yo...   \n",
       "5306  0001-08-28 22:25:35  The following reports have been waiting for yo...   \n",
       "5285  0001-09-13 22:24:08  Employee Name: Kimberly WatsonReport Name:   E...   \n",
       "8934  0001-09-17 09:24:00  The following expense report is ready for appr...   \n",
       "\n",
       "     recipient_id                 recipients  \n",
       "5304        [377]  kimberly.watson@enron.com  \n",
       "5305        [377]  kimberly.watson@enron.com  \n",
       "5306        [377]  kimberly.watson@enron.com  \n",
       "5285        [377]  kimberly.watson@enron.com  \n",
       "8934        [121]   barry.tycholiz@enron.com  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186.328\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "senders_recipients = defaultdict(lambda: set())\n",
    "for l in df.values:\n",
    "    for r in l[5]:\n",
    "        senders_recipients[l[1]].add(r)\n",
    "        \n",
    "c = 0\n",
    "for s, r in senders_recipients.iteritems():\n",
    "    c += len(r)\n",
    "print float(c)/125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48209709.0\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "senders_counts = np.zeros(125)\n",
    "for l in df.values:\n",
    "    senders_counts[l[1]] += 1\n",
    "\n",
    "print np.sum(senders_counts**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks possible (but a bit long) to train one svm per sender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here I implement this idea for each sender, and add the time as 4 additional features.\n",
    "http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim at builing a ranking generator for each sender. For this we use word2vec to get reasonable features, and we interpret the task as a regression task, using one hot encoding on the recipients. Next we might try to train an embedding on the recipients, which seems to be best solution to fit our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def ohe(y):\n",
    "    seen = set()\n",
    "    indexes = []\n",
    "    for l in y:\n",
    "        for r in l:\n",
    "            if not r in seen:\n",
    "                seen.add(r)\n",
    "                indexes.append(r)\n",
    "    rindexes = {indexes[i]: i for i in range(len(indexes))}\n",
    "    \n",
    "    y_ohe = np.zeros((len(y), len(indexes)), dtype=float)\n",
    "    for i in range(len(y)):\n",
    "        l = y[i]\n",
    "        for r in l:\n",
    "            y_ohe[i][rindexes[r]] = 1.\n",
    "    return y_ohe, indexes\n",
    "\n",
    "def make_dataset(df, w2v, d, split_ratio=.1, min_df=10):\n",
    "    stemmer = PorterStemmer\n",
    "    X, X_dates, y = df[['sender_id', 'body']].values, df['date'].values, df['recipient_id'].values\n",
    "    \n",
    "    print \"stemming...\"\n",
    "    stemmer = PorterStemmer()\n",
    "    for i in range(len(X)):\n",
    "        X[i][1] = ' '.join(map(lambda x: str(stemmer.stem(x)), word_tokenize(X[i][1])))\n",
    "    \n",
    "    print \"vectorizing...\"\n",
    "    vect = CountVectorizer(min_df=min_df, stop_words='english')\n",
    "    #vect = TfidfVectorizer(min_df=min_df, stop_words='english')\n",
    "    X_body = vect.fit_transform(X[:,1])\n",
    "    \n",
    "    print \"w2v...\"\n",
    "    voc = vect.vocabulary_\n",
    "    coef = np.array([s if s != 0. else 1. for s in X_body.sum(axis=1)])\n",
    "    translate_matrix = np.empty((len(voc), d), dtype=float)\n",
    "    for w, i in voc.iteritems():\n",
    "        translate_matrix[i] = w2v[w] if w in w2v else np.zeros(d)\n",
    "    vectorized = X_body.dot(translate_matrix)/coef.reshape(-1, 1)\n",
    "    \n",
    "    # not sure if better to divide by coef here\n",
    "    # vectorized = X_body.dot(translate_matrix)\n",
    "    \n",
    "    date_features = np.array([np.array([s[:4], s[5:7], s[8:10], s[11:13]]) for s in X_dates]).astype(float)\n",
    "    \n",
    "    X_full = np.hstack((vectorized, date_features))\n",
    "    \n",
    "    X_lol, y_lol = defaultdict(lambda: []), defaultdict(lambda: [])\n",
    "    recipient_indexes = []\n",
    "    for i in range(len(X)):\n",
    "        X_lol[X[i][0]].append(X_full[i])\n",
    "        y_lol[X[i][0]].append(y[i])\n",
    "    \n",
    "    print \"one hot encoding...\"\n",
    "    recipient_indexes = []\n",
    "    for i in range(125):\n",
    "        y_lol[i], indexes = ohe(y_lol[i])\n",
    "        recipient_indexes.append(indexes)\n",
    "        \n",
    "        \n",
    "    X_train, X_test, y_train, y_test = [], [], [], []\n",
    "    \n",
    "    for i in range(125):\n",
    "        cur_X = StandardScaler().fit_transform(np.array(X_lol[i]))\n",
    "        train_size = len(cur_X) - int(.1*len(cur_X))\n",
    "        X_train.append(cur_X[:train_size])\n",
    "        X_test.append(cur_X[train_size:])\n",
    "        cur_y = np.array(y_lol[i])\n",
    "        y_train.append(cur_y[:train_size])\n",
    "        y_test.append(cur_y[train_size:])\n",
    "        if(y_train[i].shape[1] == 1):\n",
    "            y_train[i] = y_train[i].ravel()\n",
    "            y_test[i] = y_test[i].ravel()\n",
    "    \n",
    "    train_size = len(X) - int(.1*len(X))\n",
    "    return X_train, X_test, y_train, y_test, recipient_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"glove.6B.50d.txt\", \"rb\") as lines:\n",
    "    w2v = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "           for line in lines}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stemming...\n",
      "vectorizing...\n",
      "w2v...\n",
      "one hot encoding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daemonginger/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141.879356861\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "start = time()\n",
    "X_train, X_test, y_train, y_test, recipient_indexes = make_dataset(df, w2v, 50)\n",
    "print time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ap(recommanded, real):\n",
    "    real_set = set(real)\n",
    "    cur = 0.\n",
    "    n = len(recommanded)\n",
    "    ans = 0.\n",
    "    for k in range(1, n+1):\n",
    "        if recommanded[k-1] in real_set:\n",
    "            cur += 1\n",
    "            ans += cur/k\n",
    "    return ans/min(n, len(real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 done\n",
      "Next shape is (141, 544)\n",
      "1 done\n",
      "Next shape is (351, 123)\n",
      "2 done\n",
      "Next shape is (79, 152)\n",
      "3 done\n",
      "Next shape is (112, 57)\n",
      "4 done\n",
      "Next shape is (105, 351)\n",
      "5 done\n",
      "Next shape is (75, 63)\n",
      "6 done\n",
      "Next shape is (468, 394)\n",
      "7 done\n",
      "Next shape is (99, 10)\n",
      "8 done\n",
      "Next shape is (311, 841)\n",
      "9 done\n",
      "Next shape is (76, 11)\n",
      "10 done\n",
      "Next shape is (126, 67)\n",
      "11 done\n",
      "Next shape is (63, 56)\n",
      "12 done\n",
      "Next shape is (88, 183)\n",
      "13 done\n",
      "Next shape is (365, 143)\n",
      "14 done\n",
      "Next shape is (270, 399)\n",
      "15 done\n",
      "Next shape is (94, 134)\n",
      "16 done\n",
      "Next shape is (255, 111)\n",
      "17 done\n",
      "Next shape is (546, 200)\n",
      "18 done\n",
      "Next shape is (315, 219)\n",
      "19 done\n",
      "Next shape is (91, 211)\n",
      "20 done\n",
      "Next shape is (153, 354)\n",
      "21 done\n",
      "Next shape is (471, 266)\n",
      "22 done\n",
      "Next shape is (2226, 350)\n",
      "23 done\n",
      "Next shape is (1313, 199)\n",
      "24 done\n",
      "Next shape is (470, 406)\n",
      "25 done\n",
      "Next shape is (681, 273)\n",
      "26 done\n",
      "Next shape is (151, 83)\n",
      "27 done\n",
      "Next shape is (99, 147)\n",
      "28 done\n",
      "Next shape is (400, 151)\n",
      "29 done\n",
      "Next shape is (474, 112)\n",
      "30 done\n",
      "Next shape is (436, 332)\n",
      "31 done\n",
      "Next shape is (383, 135)\n",
      "32 done\n",
      "Next shape is (298, 14)\n",
      "33 done\n",
      "Next shape is (80, 141)\n",
      "34 done\n",
      "Next shape is (313, 248)\n",
      "35 done\n",
      "Next shape is (246, 207)\n",
      "36 done\n",
      "Next shape is (172, 96)\n",
      "37 done\n",
      "Next shape is (359, 214)\n",
      "38 done\n",
      "Next shape is (70,)\n",
      "39 done\n",
      "Next shape is (417, 222)\n",
      "40 done\n",
      "Next shape is (72, 21)\n",
      "41 done\n",
      "Next shape is (80, 59)\n",
      "42 done\n",
      "Next shape is (116, 140)\n",
      "43 done\n",
      "Next shape is (173, 89)\n",
      "44 done\n",
      "Next shape is (227, 140)\n",
      "45 done\n",
      "Next shape is (367, 131)\n",
      "46 done\n",
      "Next shape is (144, 84)\n",
      "47 done\n",
      "Next shape is (134, 72)\n",
      "48 done\n",
      "Next shape is (278, 283)\n",
      "49 done\n",
      "Next shape is (144, 388)\n",
      "50 done\n",
      "Next shape is (521, 177)\n",
      "51 done\n",
      "Next shape is (94, 153)\n",
      "52 done\n",
      "Next shape is (162, 64)\n",
      "53 done\n",
      "Next shape is (61, 61)\n",
      "54 done\n",
      "Next shape is (713, 302)\n",
      "55 done\n",
      "Next shape is (621, 168)\n",
      "56 done\n",
      "Next shape is (76, 95)\n",
      "57 done\n",
      "Next shape is (181,)\n",
      "58 done\n",
      "Next shape is (148, 98)\n",
      "59 done\n",
      "Next shape is (990, 354)\n",
      "60 done\n",
      "Next shape is (97, 88)\n",
      "61 done\n",
      "Next shape is (96, 130)\n",
      "62 done\n",
      "Next shape is (89, 168)\n",
      "63 done\n",
      "Next shape is (138, 160)\n",
      "64 done\n",
      "Next shape is (841, 365)\n",
      "65 done\n",
      "Next shape is (107, 36)\n",
      "66 done\n",
      "Next shape is (1510, 417)\n",
      "67 done\n",
      "Next shape is (624, 337)\n",
      "68 done\n",
      "Next shape is (233, 130)\n",
      "69 done\n",
      "Next shape is (135, 70)\n",
      "70 done\n",
      "Next shape is (125, 86)\n",
      "71 done\n",
      "Next shape is (75, 97)\n",
      "72 done\n",
      "Next shape is (96, 76)\n",
      "73 done\n",
      "Next shape is (133, 205)\n",
      "74 done\n",
      "Next shape is (83,)\n",
      "75 done\n",
      "Next shape is (110, 75)\n",
      "76 done\n",
      "Next shape is (118, 185)\n",
      "77 done\n",
      "Next shape is (190, 87)\n",
      "78 done\n",
      "Next shape is (162, 144)\n",
      "79 done\n",
      "Next shape is (135, 82)\n",
      "80 done\n",
      "Next shape is (66, 40)\n",
      "81 done\n",
      "Next shape is (152, 83)\n",
      "82 done\n",
      "Next shape is (117, 287)\n",
      "83 done\n",
      "Next shape is (3915, 676)\n",
      "84 done\n",
      "Next shape is (313, 176)\n",
      "85 done\n",
      "Next shape is (175, 84)\n",
      "86 done\n",
      "Next shape is (1463, 826)\n",
      "87 done\n",
      "Next shape is (288, 203)\n",
      "88 done\n",
      "Next shape is (313, 284)\n",
      "89 done\n",
      "Next shape is (119, 102)\n",
      "90 done\n",
      "Next shape is (198, 84)\n",
      "91 done\n",
      "Next shape is (134, 273)\n",
      "92 done\n",
      "Next shape is (100, 242)\n",
      "93 done\n",
      "Next shape is (169, 58)\n",
      "94 done\n",
      "Next shape is (113, 57)\n",
      "95 done\n",
      "Next shape is (738, 202)\n",
      "96 done\n",
      "Next shape is (391, 460)\n",
      "97 done\n",
      "Next shape is (81, 152)\n",
      "98 done\n",
      "Next shape is (88, 81)\n",
      "99 done\n",
      "Next shape is (140, 99)\n",
      "100 done\n",
      "Next shape is (107, 77)\n",
      "101 done\n",
      "Next shape is (1284, 1247)\n",
      "102 done\n",
      "Next shape is (202, 99)\n",
      "103 done\n",
      "Next shape is (146, 133)\n",
      "104 done\n",
      "Next shape is (87, 76)\n",
      "105 done\n",
      "Next shape is (109, 245)\n",
      "106 done\n",
      "Next shape is (129, 373)\n",
      "107 done\n",
      "Next shape is (909, 453)\n",
      "108 done\n",
      "Next shape is (187, 125)\n",
      "109 done\n",
      "Next shape is (101, 120)\n",
      "110 done\n",
      "Next shape is (137, 190)\n",
      "111 done\n",
      "Next shape is (160, 185)\n",
      "112 done\n",
      "Next shape is (355, 138)\n",
      "113 done\n",
      "Next shape is (68, 51)\n",
      "114 done\n",
      "Next shape is (73, 26)\n",
      "115 done\n",
      "Next shape is (70, 67)\n",
      "116 done\n",
      "Next shape is (63, 65)\n",
      "117 done\n",
      "Next shape is (160, 176)\n",
      "118 done\n",
      "Next shape is (351, 224)\n",
      "119 done\n",
      "Next shape is (192, 116)\n",
      "120 done\n",
      "Next shape is (835, 249)\n",
      "121 done\n",
      "Next shape is (362, 133)\n",
      "122 done\n",
      "Next shape is (121, 98)\n",
      "123 done\n",
      "Next shape is (89, 73)\n",
      "124 done\n",
      "Next shape is (301, 44)\n",
      "769.109930038\n",
      "Score on test: 0.0796565305964\n",
      "Score on train: 0.183190276526\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "start = time()\n",
    "models = []\n",
    "cur = 0\n",
    "for i in range(125):\n",
    "    print(\"{} done\".format(cur))\n",
    "    print(\"Next shape is {}\".format(y_train[i].shape))\n",
    "    models.append(RandomForestRegressor(n_estimators=50, max_leaf_nodes=300).fit(X_train[i], y_train[i]))\n",
    "    cur += 1\n",
    "print time() - start\n",
    "\n",
    "y_pred = []\n",
    "for i in range(125):\n",
    "    y_pred.append(models[i].predict(X_test[i]))\n",
    "    \n",
    "score, c = 0, 0\n",
    "for i in range(125):\n",
    "    for j in range(len(y_test[i])):\n",
    "        real = np.argsort(y_test[i][j])[-10:]\n",
    "        recommanded = list(np.argsort(y_pred[i][j])[-10:])\n",
    "        while len(recommanded) < 10:\n",
    "            recommanded.append(np.max(recommanded) + 1)\n",
    "        score += ap(recommanded, real)\n",
    "        c += 1\n",
    "\n",
    "print(\"Score on test: {}\".format(score/c))\n",
    "\n",
    "y_pred_train = []\n",
    "for i in range(125):\n",
    "    y_pred_train.append(models[i].predict(X_train[i]))\n",
    "    \n",
    "score, c = 0, 0\n",
    "for i in range(125):\n",
    "    for j in range(len(y_train[i])):\n",
    "        real = np.argsort(y_train[i][j])[-10:]\n",
    "        recommanded = list(np.argsort(y_pred_train[i][j])[-10:])\n",
    "        while len(recommanded) < 10:\n",
    "            recommanded.append(np.max(recommanded) + 1)\n",
    "        score += ap(recommanded, real)\n",
    "        c += 1\n",
    "        \n",
    "print(\"Score on train: {}\".format(score/c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([38, 20, 47, 40, 35, 29, 18, 11, 17, 16, 24, 48, 26, 13, 12,  3, 49,\n",
       "        14,  7, 46, 25, 39, 19, 27, 44,  2, 45,  8,  5,  1, 36, 34, 37, 41,\n",
       "        21, 52, 23, 22, 53, 32, 43,  0, 31,  4, 15, 28,  6, 30, 10, 42,  9,\n",
       "        51, 33, 50]),\n",
       " array([ 0.15898292,  0.14493459,  0.09903551,  0.04498742,  0.0439194 ,\n",
       "         0.04068918,  0.03101346,  0.03048066,  0.02914683,  0.02686461,\n",
       "         0.02177885,  0.02126114,  0.02085528,  0.0183163 ,  0.01774724,\n",
       "         0.01701305,  0.01600744,  0.01420805,  0.01322368,  0.01249123,\n",
       "         0.01205261,  0.01169876,  0.01156549,  0.01110409,  0.01085911,\n",
       "         0.0100729 ,  0.00996809,  0.00964845,  0.00769202,  0.00722216,\n",
       "         0.0071816 ,  0.00686154,  0.00655002,  0.00611224,  0.00500391,\n",
       "         0.00453447,  0.00363094,  0.00358627,  0.00314438,  0.00299074,\n",
       "         0.00298612,  0.00277851,  0.00259674,  0.00228275,  0.00226095,\n",
       "         0.00222349,  0.00209709,  0.00196365,  0.0018023 ,  0.0014566 ,\n",
       "         0.00143284,  0.00104265,  0.00063967,  0.        ]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(models[0].feature_importances_)[::-1], np.sort(models[0].feature_importances_)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.9938843787299956"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][0][51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([51, 52, 53, 33,  9, 37, 47, 24, 26, 43, 35, 11, 30, 25, 13, 12, 44,\n",
       "        23, 42,  6, 31,  5, 45, 49, 50, 46, 27, 20,  0,  8, 17, 15, 16, 34,\n",
       "        41,  3, 29, 21,  2, 10, 38, 14, 28, 32,  7,  4, 36, 18, 19, 48,  1,\n",
       "        39, 22, 40]),\n",
       " array([ 0.0599165 ,  0.0473159 ,  0.04363581,  0.0412366 ,  0.03679398,\n",
       "         0.02962343,  0.02944725,  0.02757881,  0.0264243 ,  0.02560782,\n",
       "         0.0255568 ,  0.02331099,  0.02326877,  0.02313611,  0.02225735,\n",
       "         0.01979412,  0.0195791 ,  0.01943066,  0.01796719,  0.01756959,\n",
       "         0.01726809,  0.01669323,  0.01625402,  0.01608755,  0.01584779,\n",
       "         0.01580132,  0.01563665,  0.01558137,  0.01513603,  0.01361722,\n",
       "         0.01360294,  0.01353925,  0.01345529,  0.01312137,  0.01277925,\n",
       "         0.01241071,  0.01225903,  0.01194206,  0.01186344,  0.01169529,\n",
       "         0.01162795,  0.01162045,  0.01155281,  0.01104398,  0.01099812,\n",
       "         0.01097765,  0.01025029,  0.01004152,  0.00981778,  0.00940808,\n",
       "         0.00907113,  0.00808588,  0.00746043,  0.00400097]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(models[1].feature_importances_)[::-1], np.sort(models[1].feature_importances_)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
